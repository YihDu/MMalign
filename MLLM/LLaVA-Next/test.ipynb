{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c92e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c75edc0654baaabe7d5373654116e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: \n",
      "What is shown in this image? ASSISTANT: The image appears to be a scatter plot graph, which is a type of data visualization that uses dots to represent the values of a set of variables for a collection of cases. Each dot represents an observation, and the position of the dot on the graph is determined by the values of the variables it represents.\n",
      "\n",
      "In this particular graph, there are several variables represented by different colors and symbols:\n",
      "\n",
      "- The x-axis represents a variable labeled \"MMME,\" which could stand\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(\"/root/hf_models/LLaVA-Next/7B\")\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\"/root/hf_models/LLaVA-Next/7B\", torch_dtype=torch.float16, low_cpu_mem_usage=True) \n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "# prepare image and text prompt, using the appropriate prompt template\n",
    "url = \"https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Define a chat histiry and use `apply_chat_template` to get correctly formatted prompt\n",
    "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\") \n",
    "conversation = [\n",
    "    {\n",
    "\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "          {\"type\": \"text\", \"text\": \"What is shown in this image?\"},\n",
    "          {\"type\": \"image\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "# autoregressively complete prompt\n",
    "output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QwenVL25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
